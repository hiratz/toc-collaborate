\appput{caching}{Cache Complexity Analysis of Loop-based algorithm and recursion based algorithm}

%\subsubsecput{CacheModel}{An Ideal distributed cache model}
In this appendix, we will analyze the cache complexity of both loop-based algorithm and recursion based
algorithm based an ideal distributed cache model published in \cite{FrigoSt09}. Something we need to
explicitly state are that we use FIFO as the underlying cache replacement strategy to ease the analysis;
in this analysis, we just count the cache read misses, because the write misses as we will see in the analysis
are be trivial if we are pursuing a minimum cache miss ratio. Also, in this paper, we don't consider the effect
of prefetching.

In following analysis, we only consider stencil that is of $1$ spatial dimensional and the computation of stencil
only requires the data of one previous time step.That is, there are at most $2$ toggle array used in stencil computation.

%
%\begin{mydef}
%\emph{\bf Ideal Distributed Cache Model:} An ideal distributed cache model must have following properties:
%\begin{itemize}
%	\item It has only $2$-level memory hierarchy
%	\item It has infinite number of processors, each equipped with
%          a private ideal cache, which is connected to an arbitrary
%          large shared main memory
%	\item An ideal cache is fully associative which means one
%          element of data can be stored in any location in the cache,
%          and implements the cache replacement strategy as a
%          \emph{FIFO}
%	\item each private cache contains $Z$ words (the cache size)
%          and it's partitioned into cache lines consisting of $L$
%          (assuming = 1) consecutive words.
%	\item A processor can only access its private local cache, if
%          the data is not available in the cache, it's a \emph{miss}
%	\item When completing a segment (process), a processor
%          completely invalidates and flushes its own cache (but not
%          other caches), which leads to a burst of cache write
%          miss. In this paper, we do NOT count the cache misses
%          incurred by the last flush. We currently only count the
%          cache read miss.
%	\item In ideal distributed cache model, we don't count the
%          effect of prefetching.
%\end{itemize}
%\label{def:cacheModel}
%\end{mydef}

\subsubsecput{CacheComplexity}{Cache complexity} We first give out following
definitions we will use to analyze the cache complexity of different
algorithms:

\begin{mydef}
\emph{\bf Cache Complexity $Q_{miss}$:} \cite{FrigoSt09} we define cache complexity
$Q_{miss}$ as the total number of cache read miss incurred by an
entire computation running on an ideal distributed cache model
(\defref{cacheModel}), starting and ending with an empty cache.
\label{def:cacheMiss}
\end{mydef}

\begin{mydef}
\emph{\bf $Q_{total}$:} we define $Q_{total}$ as the total number of
memory access in the entire computation, including both cache misses
and cache hits.
\label{def:cacheTotal}
\end{mydef}

We raise a new metric $ratio_{reuse}$ to measure the cache efficiency
of any algorithm running on an ideal distributed cache model. This
metric can clearly and explicitly tell us which algorithm has better 
cache efficiency.

\begin{mydef}
\emph{\bf $ratio_{reuse} = 1 - \frac{Q_{miss}}{Q_{total}}$}
\end{mydef}

%\subsubsecput{CacheAnalysisB}{Cache complexity analysis of different parallel stencil algorithms}

\begin{theorem}
For arbitrary $d+1$-dimensional space-time grid, the parallel
cache-oblivious stencil algorithm employing no matter sequential space
cut or simultaneous space cut algorithm for space cut have the same
cache complexity $Q_{miss}$ and same reuse ratio $ratio_{reuse}$.
\label{thm:cacheSeqSim}
\end{theorem}

\begin{proof}
Apparently, both sequential space cut algorithm and simultaneous space
cut algorithm will cut all spatial grids into same number of and same
sized sub-grids. The only difference is that simultaneous space cut
removes some un-necessary \func{sync} based on real data dependences. 
So, apparently, the conclusion is trivially satisifed.
\end{proof}

%figures
\begin{figure}[htp]
\begin{center}
\subfigure[A typical black trapezoid, where $dx_0 \geq 0$ and $dx_1 \leq 0$]{\includegraphics[clip,scale=0.6]{figures/bottom_trapezoid.eps} \label{fig:bottomTrapezoid}}
\subfigure[A typical black trapezoid, for \lemref{bottomTrapezoid} \caseref{bottomTrapezoid1}]{\includegraphics[clip,scale=0.6]{figures/bottom_trapezoid_case1.eps} \label{fig:bottomTrapezoid1}}
\subfigure[A typical black trapezoid, for \lemref{bottomTrapezoid} \caseref{bottomTrapezoid2}]{\includegraphics[clip,scale=0.6]{figures/bottom_trapezoid_case2.eps} \label{fig:bottomTrapezoid2}}
\subfigure[A typical grap trapezoid, for \lemref{topTrapezoid}]{\includegraphics[clip,scale=0.6]{figures/top_trapezoid.eps} \label{fig:topTrapezoid}}
\subfigure[A typical square trapezoid, for \corref{squareTrapezoid}]{\includegraphics[clip,scale=0.6]{figures/square_trapezoid.eps} \label{fig:squareTrapezoid}}
\end{center}
\label{fig:Trapzoids}
\caption{Various Trapezoids}
\end{figure}

\begin{lemma}
For a black trapezoid $T(t_0, t_1, x_0, x_1, dx_0, dx_1)$, that is,
$dx_0 \geq 0$ and $dx_1 \leq 0$ (see \figref{bottomTrapezoid}), if the
algorithm visit all the points in this black trapezoid bottom up, from
left to right, the minimum cache read miss will be $Q_b =
w_{b\bot} + 2 \sigma \leq \frac{1}{2} Z + \sigma$, 
where $w_{b\bot} = x_1 - x_0$ is the length of bottom bar of the black trapezoid.
\label{lem:bottomTrapezoid}
\end{lemma}

\begin{proof}
We consider three (3) different cases:

\begin{enumerate}

	\item \label{case:bottomTrapezoid1} 
		  If $w_{b\bot} + w_{b\bot} + 2 \sigma \leq Z$ 
		  (see \figref{bottomTrapezoid1}): Because there are
          only $2$ toggled arrays used in stencil computation, and the
          trapezoid is computed bottom up. So we at most need to
          consider the cache misses in two consecutive time
          steps. Because $dx_0 \geq 0$ and $dx_1 \leq 0$, apparently,
          the bottom two lines of computation will incur the most
          computation and memory access. To compute each point in the 
          bottom bar, it will have $2 \sigma + 1$ memory access, however,
          it's easy to know that except for the first point in the bottom bar,
          the computation of the rest points in the bottom bar will incur
          only $1$ cache miss, because it can reuse all the data fetched in
          computing its immediate preceding neighbor. And the first point of
          bottom bar will incur $2 \sigma + 1$ cache misses. So, the computation
          of bottom bar will incur only $w_{b\bot} + 2 \sigma$ cache misses.
          Because $dx_0 \geq 0$ and $dx_1 \leq 0$, and we use toggle array 
          alternatively to compute the points in subsequent time steps, all
          memory access in the computation of subsequent time steps will just
          reuse the existing data without any miss. 
          That is, we have inductive equations:
            \begin{equation}
			\begin{array}{l}
				Q_{timestep_0} = w_{b\bot} + 2 \sigma \\
				Q_{timestep_1} = Q_{timestep_0} \\
				\cdots \\
				Q_{timestep_i} = Q_{timestep_{i-1}} \\
				\cdots \\
				Q_{timestep_{h-1}} = Q_{timestep_{h-2}} 
			\end{array} \label{eq:upTrapezoidCacheInduction}
			\end{equation}
          where time step is counted bottom up, and $h = t_1 - t_0$.
          We can easily see that the entire cache miss will be equivalent to that incurred by
          computation of the bottom bar, that is, $Q_b = Q_{timestep_{h-1}} = w_{b\bot} + 2 \sigma $.
          Because $w_{b\bot} + w_{b\bot} + 2 \sigma \leq Z$, we have
          $Q_b \leq \frac{1}{2} Z + \sigma$

	\item \label{case:bottomTrapezoid2} 
		  If $w_{b\bot} + w_{b\bot} + 2 \sigma > Z$ 
		  and $w_{b\top} + w_{b\top} + 2 \sigma \leq Z$, where $w_{b\top}$ is the length
		  of the top bar of black trapezoid. From the
          condition, we can easily know that $\exists w', w_{b\top} < w' \leq
          w_{b\bot}, s.t. w' + w' + 2 \sigma \leq Z$ holds. 
          So, we can divide the big trapezoid
          $Q$ into two sub-trapezoids $Q_1$ and $Q_2$ according to the
          width of $w'$. \label{case:bottomTrapezoid2}
	\begin{itemize}
		\item For $Q_1$, the top bar is still $w_{b\top}$, bottom bar is $w'$, from
		\caseref{bottomTrapezoid1}, we have
		\begin{eqnarray}		
		w' + w' + 2 \sigma & \leq & Z \\
		Q_1  & = & w' + 2 \sigma \\
			 & = & \frac{1}{2} Z + \sigma
		\end{eqnarray}

		\item For $Q_2$, we have$\forall w'', w' < w'' \leq w_{b\bot}, s.t. 
				  w'' + w'' + 2 \sigma > Z$. Because we organize the ideal cache as a
                  FIFO, so the sweep through each line of the
                  trapezoid will cause a repetitive
                  cache read miss. So the entire cache read miss in
                  $Q_2$ will be the area of $Q_2$. We
                  have: \label{case:bottomTrapezoid2}
		\item $Q_{miss} = Q_1 + Q_2 \geq Q_1 = \frac{1}{2} Z + \sigma$
	\end{itemize} 

	\item If $w_{b\top} + w_{\top} + 2 \sigma > Z$, where $w_{b\top}$ is the length
		  of top bar of black trapezoid. From above
          \caseref{bottomTrapezoid2}, we can easily know that
          $Q_b$ equals entire area of
          trapezoid. So: $Q_b > \frac{1}{2} Z + \sigma$\label{case:bottomTrapezoid3}
\end{enumerate}

From above three (3) cases, follows the conclusion that the minimum cache read miss can be
achieved only when $w_{b\bot} + w_{b\bot} + 2 \sigma \leq Z$, 
and at this condition, the maximum cache read miss will be
$Q_b = w_{b\bot} + 2 \sigma \leq \frac{1}{2} Z + \sigma$
\end{proof}

\begin{lemma}
For a strict gray trapezoid $T(t_0, t_1, x_0, x_1, dx_0, dx_1)$, that is,
$dx_0 < 0$ and $dx_1 > 0$ (see \figref{topTrapezoid}), if the
algorithm visit all the points in this gray trapezoid bottom up, from
left to right, the minimum cache read miss will be $Q_g =
2 w_{g\top} - w_{g\bot} - 2 \sigma \leq Z - 4 \sigma$, 
where $w_{g\top} = (x_1 + dx_1 \times (t_1 - t_0)) - (x_0 + dx_0 \times (t_1 - t_0))$ 
is the length of top bar of gray trapzoid, $w_{g\bot} = x_1 - x_0$ is the length of bottom
bar of gray trapezoid.
\label{lem:topTrapezoid}
\end{lemma}

\begin{proof}
We still divide the proof into three (3) different cases:
\begin{enumerate}
	\item \label{case:topTrapezoid1}
		  If $w_{g\top} + w_{g\top} + 2 \sigma \leq Z$: Now, the
          bottom bar is the shortest time step of the 
          trapezoid computation, from the analysis of
          \lemref{bottomTrapezoid} \caseref{bottomTrapezoid1}the
          computation of all points in this bottom bar will incur $(x_1
          - x_0) + 2 \sigma$ cache read misses. From bottom up, the
          computation of all points in each time step will incur at
          least the cache read misses of previous time step plus 
          $2 \times (2 \sigma + 1) - 2 = 4 \sigma$ 
          for the begining and end point of current time
          step. If we let $h = t_1 - t_0$ be the height of the trapezoid,
          we will have following inductive equations: 
			\begin{equation}
			\begin{array}{l}
				Q_{timestep_0} = w_{g\bot} + 2 \sigma \\
				Q_{timestep_1} = Q_{timestep_0} + 4 \sigma \\
				\cdots \\
				Q_{timestep_i} = Q_{timestep_{i-1}} + 4 \sigma \\
				\cdots \\
				Q_{timestep_{h-1}} = Q_{timestep_{h-2}} + 4 \sigma
			\end{array}
			\label{eq:upTrapezoidCacheInduction}
			\end{equation}
          where time step is counted bottom up. 
          By solving the induction, we have 
          \begin{equation}
          \begin{array}{l}
          Q_g = Q_{timestep_{h-1}}= w_{g\bot} + 4 \sigma \times (h-1) + 2 \sigma \\
          w_{g\top} = w_{\bot} + 2 \sigma h \\
          2 w_{g\top} + 2 \sigma \leq Z \\
          w_{g\bot} \geq 0
          \end{array}
          \end{equation}
          We will have $Q_g = 2 w_{g\top} - w_{g\bot} - 2 \sigma \leq 2 w_{g\top} - 2 \sigma \leq Z - 4 \sigma$
	\item \label{case:topTrapezoid2} If $w_{g\top} + w_{g\top} + 2
          \sigma > Z$ and $w_{g\top} - 2 \sigma h + w_{g\top} - 2 \sigma
          h + 2 \sigma \leq Z$: That is, the top bar of the trapezoid
          and its toggled array is larger than cache size $Z$, while
          the bottom bar of the trapezoid and its toggled array is
          smaller than $Z$. By an analogous analysis as
          \lemref{bottomTrapezoid} \caseref{bottomTrapezoid2}, we can
          get $Q_g= Q_1 + Q_2$ will be larger than the
          $Q_g$ in above \caseref{topTrapezoid1}
	
	\item \label{case:upTrapezoid3} If $w_{g\top} + w_{g\top} + 2
          \sigma > Z$, we can have a similar analysis as in
          \lemref{bottomTrapezoid} \caseref{bottomTrapezoid3} and can
          easily see that the cache miss $Q_g$ will the area of
          entire trapezoid, so it will be much larger than the
          $Q_g$ in above \caseref{topTrapezoid1}
\end{enumerate}
From above three (3) cases, follows the conclusion that the minimum cache read miss can be
achieved only when $w_{g\top} + w_{g\top} + 2 \sigma \leq Z$, 
and at this condition, the maximum cache read miss will be
$Q_g = 2 w_{g\top} - w_{g\bot} - 2 \sigma \leq Z - \frac{7}{2} \sigma$
\end{proof}

\begin{corollary}
For a square-shaped trapezoid $T(t_0, t_1, x_0, x_1, dx_0, dx_1)$,
that is $dx_0 = 0$ and $dx_1 = 0$, the minimum cache miss $Q = w + 2
\sigma h$, where $w = x_1 - x_0$.
\label{cor:squareTrapezoid}
\end{corollary}

\begin{proof}
For a square-shaped trapezoid, we can treat it as a special case of
\lemref{bottomTrapezoid}. So the minimum cache miss is achieved only
when $w + w + 2 \sigma \leq Z$. By \lemref{bottomTrapezoid}
\caseref{bottomTrapezoid1}, we get our conclusion.
\end{proof}

\begin{theorem}
For blocked parallel loop algorithm for stencil computation. Assuming there
are infinite number of processors/cores, the
lower bound of minimum cache miss is $Q \geq \frac{12 \sigma N T}{Z - 2 \sigma}$, 
and upper bound for data reuse ratio is 
$ratio_{reuse} \leq 1 - \frac{12 \sigma}{(Z - 2 \sigma)(2 \sigma + 1)}$
where $T$ is the total number of
time steps, $N$ is the total number of spatial points in one time
step. $w_{\top}$ is the shortest bar of a trapezoid, usually the width
of top bar of black trapezoid (\figref{bottomTrapezoid}) or bottom bar
of gray trapezoid (\figref{topTrapezoid}), $w_{\bot}$ is the longest
bar of a trapezoid, ususally the width of top bar of gray trapezoid
(\figref{topTrapezoid}) or bottom bar of black trapezoid
(\figref{bottomTrapezoid}). We also assume that in space cut, we will
cut the black trapezoid and gray trapezoid to have same area.
\label{thm:loopAlgor}
\end{theorem}

\begin{figure}[ht]
\centerline{\mbox{\includegraphics[clip,scale=0.6]{figures/parallel_loop_algor.eps}}}
\caption{Illustration of blocked parallel loop algorithm}
\label{fig:pLoopAlgor}
\end{figure}

\begin{proof}
For blocked parallel loop algorithm, we first cut into time dimension
to get fixed length strips of spatial dimensions. Then we cut into spatial
dimension of those strips to get the tiling as \figref{pLoopAlgor}
shows.

If we assume all black and gray trapezoids are of the same size. And for 
each space cut, we cut into $r$ pairs of black and gray trapezoids. Then we have
\begin{equation}
w_{\bot} + w_{\top} = N/r \label{eq:cond0}
\end{equation}

From \lemref{bottomTrapezoid}
\caseref{bottomTrapezoid1}, in order to minimize the cache miss in
each pair of black and gray trapezoid, we must have inequality \eqref{cond1} hold:
\begin{equation}
w_{\bot} + w_{\bot} + 2 \sigma \leq Z \label{eq:cond1} \\
\end{equation}

And at that time, the cache miss of the pair of black and gray trapezoids are:
\begin{equation}
Q_{pair} = 3 w_{\bot} - w_{\top} \label{eq:cond2}
\end{equation}

By geometric property of trapezoid, we have following condition:
\begin{equation}
w_{\bot} = w_{\top} + 2 \sigma h \label{eq:cond3} 
\end{equation}

And the for the entire region, $Q_{miss}$ can be calculated as following:
\begin{equation}
Q_{miss} = (T/h) \times r \times Q_{pair} \label{eq:qLoop}
\end{equation}

By combining \eqref{cond0} \eqref{cond2} \eqref{cond3} into \eqref{qLoop}, we get:
\begin{eqnarray}
w_{\bot} & = & \frac{N}{2r} + \sigma h \\
w_{\top} & = & \frac{N}{2r} - \sigma h \\
Q_{pair} & = & 3 w_{\bot} - w_{\top} \\
Q_{miss} & = & \frac{T}{h} \times r \times Q_{pair} \\
		 & = & \frac{T}{h} \times r \times (3 w_{\bot} - w_{\top}) \\
		 & = & \frac{T}{h} \times r \times (3 \times (\frac{N}{2r} + \sigma h) - (\frac{N}{2r} - \sigma h)) \\
		 & = & \frac{T}{h} \times r \times (\frac{N}{r} + 4 \sigma h) \\
		 & = & \frac{T \cdot N}{h} + T \cdot r \cdot 4 \sigma \label{eq:qLoop1}
\end{eqnarray}

To further simplify the discussion, let's make $w_{\top} = 0$.
From $w_{\top} = \frac{N}{2r} - \sigma h$, we have $N/h = 2 \sigma r$.
Putting this condition into \eqref{qLoop1}, we have 
\begin{equation}
Q_{miss} = 6 T \cdot r \cdot \sigma \label{eq:qLoop2}
\end{equation}

Because, when we make $w_{\top} = 0$, from \eqref{cond0}, we have 
$w_{\bot} = N/r$, plus \eqref{cond1},
we have $r \geq \frac{N}{\frac{1}{2} Z - \sigma}$. Putting into \eqref{qLoop2}, 
we have the lower bound $Q_{miss} \geq \frac{12 \sigma N T}{Z - 2 \sigma} $
So, 

\begin{eqnarray}
Q_{total} & = & (2 \sigma + 1) \cdot T \cdot N \\
ratio_{reuse} & = & 1 - \frac{Q_{miss}}{Q_{total}} \\
			  & \leq & 1 - \frac{12 \sigma}{(Z - 2 \sigma)(2 \sigma + 1)}
\end{eqnarray}

Apparently, assuming there're infinite number of processors/cores, the reuse ratio blocked loop-based
algorithm will be upper-bounded by the size of cache only.
\end{proof}

\begin{theorem}
For un-coarsened cache-oblivious stencil algorithm, assuming there are infinite number of processors/cores,
we have the lower bound of minimal cache miss 
$Q_{miss} \geq \Theta (\frac{(4 \sigma T)^2 \cdot (2 \sigma + 1)}{N}) = \Theta (\frac{T^2}{N})$,
and upper bound for data reuse ratio
$ratio_{reuse} \leq 1 - \frac{16 \sigma^2 T}{N^2}$
\label{thm:coUncoarsened}
\end{theorem}

\begin{proof}
In order to prove the conclusion, we need to simplify the algorithm to eliminate conditional branches 
in the recursion of original algorithm. That is, we first assume that the initial grid $T(t_0, t_1, x_0, x_1, dx_0, dx_1)$ is large enough then we need to first cut into time dimension before we can cut into spatial dimension. 
And for the subsequent cut, we cut into space and time alternatively so to eliminate the conditional branches in
the orignal algorithm. In order for this alternative cuts to happen, each time we cut into time dimension, we cut
it into $t$ sub-trapezoids of the same volume, such that any of these $t$ sub-trapezoids will be either qualified 
to be a base case computation, or qualified to have an immediate space cut. Such a $t$ must exist because, in the
worst case, we can always cut the time dimension into sub-trapezoids of height $1$ to satisfy the requirement. 
Although cutting the sub-trapezoid to be of height $1$ won't make them of same volume, but the result should be 
asymptotically close.

So, we will have following recurrence:
\begin{eqnarray}
Q_{miss} & = & (T/h_{can\_cut}) \times (r \times Q_{space}(\frac{T \cdot N}{h_{can\_cut} \cdot r})) \\
Q_{space}(n) & = & t Q_{time}(n/t) \\
Q_{time}(n) & = & r \cdot Q_{space}(\frac{n}{r}) \\
Q_{space}(1) & = & 2 \sigma + 1 \label{eq:rec1}
\end{eqnarray}
where $r \geq 2$ is the number of black/gray sub-trapezoid pair generated for each space cut. If $r = 1$, then
the space cut won't generate any smaller sub-trapezoid, the recursion can't continue.

Using the master method to solve the recurrence, we get
\begin{eqnarray}
Q_{space}(n) & = & \Theta (n) \\
Q_{miss} & = & (T/h_{can\_cut}) \times (r \times Q_{space}(\frac{T \cdot N}{h_{can\_cut} \cdot r})) \\
		  & = & \Theta ((T/h_{can\_cut}) \times (r \times (2 \sigma + 1) \cdot (\frac{T \cdot N}{h_{can\_cut} \cdot r}))) \\
		  & = & \Theta (\frac{(2 \sigma + 1) \cdot T^2 \cdot N}{h_{can\_cut}^2}) \label{eq:coTotal}
\end{eqnarray}

So, in order to minimize $Q_{total}$, we have to maximize $h_{can\_cut}$, so we have equations:
\begin{eqnarray}
w_{\bot} & = & w_{\top} + 2 \sigma h \\
w_{\bot} + w_{\top} & = & N/r \\
w_{\top} & \geq & 0 \\
\Rightarrow h_{can\_cut} & \leq & \frac{N}{2 \sigma r} \label{eq:coHCanCut}
\end{eqnarray}

Putting \eqref{coHCanCut} into \eqref{coTotal}, we have
\begin{equation}
Q_{miss} \geq \Theta (\frac{(2 \sigma r T)^2 \cdot (2 \sigma + 1)}{N})
\end{equation}

Because $r \geq 2$, so we have
\begin{equation}
Q_{miss} \geq \Theta (\frac{(4 \sigma T)^2 \cdot (2 \sigma + 1)}{N}) = \Theta (\frac{T^2}{N})
\end{equation}

So,
\begin{eqnarray}
Q_{total} & = & (2 \sigma + 1) \cdot T \cdot N \\
ratio_{reuse} & = & 1 - \frac{Q_{miss}}{Q_{total}} \\
			  & \leq & 1 - \frac{16 \sigma^2 T}{N^2}
\end{eqnarray}

Usually, we assume $N \gg Z$, so unless $T \sim N^2$, otherwise, the reuse ratio of cache oblivious algorithm
will be worse than that of blocked loop-based algorithm.
\end{proof}

\begin{theorem}
For properly coarsened cache-oblivious stencil algorithm, assuming there are infinite number of processors/cores,
we have the same lower bound for minimal
cache miss as un-coarsened cache-oblivious stencil algorithm: 
$Q_{miss} \geq \Theta (\frac{(4 \sigma T)^2 \cdot (2 \sigma + 1)}{N}) = \Theta (\frac{T^2}{N})$
and same data reuse ratio 
$ratio_{reuse} \leq 1 - \frac{16 \sigma^2 T}{N^2}$
\label{thm:coCoarsened}
\end{theorem}
\begin{proof}
For properly coarsened cache-oblivious algorithm, we have the same recurrence similar to \eqref{rec1}:
\begin{eqnarray}
Q_{miss} & = & (T/h_{can\_cut}) \times (r \times Q_{space}(\frac{T \cdot N}{h_{can\_cut} \cdot r})) \\
Q_{space}(n) & = & t Q_{time}(n/t) \\
Q_{time}(n) & = & r \cdot Q_{space}(\frac{n}{r}) \\
\end{eqnarray}

The main difference from \thmref{coUncoarsened} is that we may stop the recursion earlier to reduce the
excessive recursive function call. From \lemreftwo{bottomTrapezoid}{topTrapezoid}, we can see that a proper
point to stop recursion is when 
\begin{eqnarray}
w_{b\bot} + w_{b\bot} + 2 \sigma & \leq & Z \\
w_{g\top} + w_{g\top} + 2 \sigma & \leq & Z
\end{eqnarray}

If we assume we cut black trapezoid and gray trapezoid of same size, and let $w_{\bot} = w_{b\bot} = w_{g\top}$, 
we have the stop condition :

\begin{equation}
w_{\bot} \leq \frac{1}{2} Z - \sigma
\end{equation}

If we let $w_{\top} = 0$, we will have
\begin{eqnarray}
w_{\bot} = 2 \sigma h_{stop} & \leq & \frac{1}{2} Z - \sigma \\
h_{stop} & \leq & \frac{Z}{4 \sigma} - \frac{1}{2}
\end{eqnarray}

And at this time, the cache miss will be
\begin{equation}
Q_{pair} = Q_b + Q_g = 3 w_{\bot} - w_{\top} = \frac{N}{r} + 4 \sigma h_{stop} \label{eq:rec2}
\end{equation}

From \lemreftwo{bottomTrapezoid}{topTrapezoid}, we have 
\begin{equation}
Q_{pair} = Q_b + Q_g \leq (\frac{1}{2} Z + \sigma) + (Z - 4 \sigma) = \frac{3}{2} Z - 3 \sigma 
\end{equation}

So, at this time, we have equation
\begin{eqnarray}
Q_{miss} & = & \frac{T}{h_{can\_cut}} \times r \times (t \cdot r)^x \times Q_{space}(\frac{T \cdot N}{h_{can\_cut} \cdot r} / (t \cdot r)^x) \\
x & = & \frac{h_{can\_cut}}{h_{stop}} \\
h_{can\_cut} & \leq & \frac{N}{2 \sigma r} \\
h_{stop} & \leq & \frac{Z}{4 \sigma} - \frac{1}{2}
\end{eqnarray}

So, we have 
\begin{eqnarray}
Q_{miss} & = & \frac{T}{h_{can\_cut}} \times r \times (t \cdot r)^x \times (6 \sigma h_{stop}) \\
x & = & \frac{h_{can\_cut}}{h_{stop}} \\
h_{can\_cut} & \leq & \frac{N}{2 \sigma r} \\
h_{stop} & \leq & \frac{Z}{4 \sigma} - \frac{1}{2} \\
\Rightarrow Q_{miss} & = & \Theta (\frac{3 \sigma r^2 T Z \cdot (t \cdot r)^{\frac{N}{Z}}}{N})
\end{eqnarray}
\end{proof}

%\begin{corollary}
%Cache-oblivious algorithm is really cache-oblivious, coarsening won't change the cache complexity of the algorithm
%\end{corollary}
%\begin{proof}
%From \thmref{coUncoarsened} and \thmref{coCoarsened}, it's trivially true.
%\end{proof}

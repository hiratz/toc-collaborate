% -*- Mode: LaTeX -*-
\secput{intro}{Introduction}

Pochoir (pronounced ``PO-shwar'') is a compiler and run-time system
for implementing stencil computations on multicore processors.  A
\defn{stencil} defines the value of a grid point in a $d$-dimensional
spatial grid at time $t$ as a function of neighboring grid points at
recent times before~$t$.  A \defn{stencil computation}
\cite{FrigoSt05, FrigoSt09, DattaMuVo08, KamilShDa06, KamilShHu05,
  Nitsure06, KrishnamoorthyBaBo07, DursunNoWa09, PengSeNo09,
  DursunNoPe09, BleckRoDi92, NakanoKaVa92, TafloveHa00, WilliamsCaOl08
} computes the stencil for each grid point over many time steps.

Stencil computations are conceptually simple to implement using nested
loops, but looping implementations suffer from poor cache performance.
Cache-oblivious \cite{FrigoLePr99,Prokop99} divide-and-conquer stencil
codes \cite{FrigoSt05, FrigoSt09} are much more efficient, but they
are difficult to write, and when parallelism is factored into the mix,
most application programmers do not have the programming skills or
patience to produce efficient multithreaded codes.

As an example, consider how the 2D
\defn{heat equation} \cite{Epperson07}
\begin{equation}
  \frac{\partial u_t(x,y)}{\partial t} 
    = \alpha \paren{\frac{\partial^2 u_t(x,y)}{ \partial x^2} 
      + \frac{\partial^2 u_t(x,y)}{ \partial y^2}}
      \label{eq:heat2d}
\end{equation}
on an $X\times Y$ grid, where $u_t(x,y)$ is the heat at a point
$(x,y)$ at time $t$ and $\alpha$ is the thermal diffusivity, might be
solved using a stencil computation.  By discretizing space and time,
this partial differential equation can be solved approximately by
using the following update equation:
\begin{eqnarray}
  u_{t+1}(x,y)  & = & u_t(x,y) \nonumber\\
  & & +  \frac{\alpha \Delta t}{\Delta x^2}
  \paren{ u_t(x-1,y) + u_t(x+1,y) - 2 u_t(x,y)}\nonumber \\
  & &  + \frac{\alpha \Delta t}{\Delta y^2} 
  \paren{u_t(x,y-1) + u_t(x,y+1) - 2u_t(x,y)} \ .
  \label{eq:heat2d-update}
\end{eqnarray}
  
One simple parallel program to implement the stencil of
\eqref{heat2d-update} is with a triply nested loop, as shown in
\figref{loops-code}.  The code is invoked as $\proc{Loops}(u; 0, T; 0,
X; 0, Y)$ to perform the stencil computation over $T$ time steps.
Although the loop indexing the time dimension is serial, the loops
indexing the spatial dimensions can be parallelized.  (As a practical
matter, only the outer loop needs to be parallelized.)  There is
generally no need to store the entire space-time grid, and so the code
uses two copies of the space grid, swapping their roles on alternate
time steps.  This code assumes that the boundary conditions are
\defn{periodic}, meaning that the space grid wraps around to form a
torus, and hence the index calculations for $x$ and $y$ are performed
modulo $X$ and $Y$, respectively.

This loop nest is simple and fairly easy to understand, but its
performance may suffer from poor cache locality.  Let $\cal M$ be the
number of grid points that fit in cache, and let $\cal B$ be the
number of grid points that fit on a cache line.  If the space grid
does not fit in cache --- that is, $XY\gg \cal M$ --- then this simple
computation incurs $\Theta(TXY/\cal B)$ cache misses in the
ideal-cache model~\cite{FrigoLePr99}.

\begin{figure}
\small
\begin{codebox}
\Procname{$\proc{Loops}(u; t_0, t_1; x_0, x_1; y_0, y_1)$}
\li       \For $t \gets t_0$ \To $t_1-1$ 
\li          \Do \Parfor $x \gets x_0$ \To $x_1-1$
\li             \Do \Parfor $y \gets y_0$ \To $y_0-1$
\li                 \Do $u((t+1)\bmod 2,x,y) \gets u(t\bmod 2,x,y) $
\zi  $\embox + \id{CX}\cdot ( u(t\bmod 2, (x-1)\bmod X, y) $
\zi  $\embox + u(t\bmod 2, (x+1)\bmod X, y) -2 u (t\bmod 2, x, y) ) $
\zi  $\embox + \id{CY}\cdot ( u(t\bmod 2, x, (y-1)\bmod Y) $
\zi  $\embox + u(t\bmod 2, x, (y+1)\bmod Y) -2u(t\bmod 2, x, y) )$
\End\End\End
\end{codebox}

\caption{A parallel looping implementation of a stencil computation
  for the 2D heat equation with periodic boundary conditions.  The
  array $u$ keeps two copies of an $X\times Y$ array of grid points,
  one for time $t$ and one for time $t+1$.  The parameters $t_0$ and
  $t_1$ are the beginning and ending time steps, and $x_0$, $x_1$,
  $y_0$, and $y_1$ are the coordinates defining the region of the
  array $u$ on which to perform the stencil computation.  The
  constants $\id{CX}=\alpha \Delta t/\Delta x^2$ and $\id{CY}=\alpha
  \Delta t/\Delta y^2$ are precomputed.  The call $\proc{Loops}(u; 0,
  T; 0, X; 0, Y)$ performs the stencil computation over the whole 2D
  array for $T$ time steps.}
\label{fig:loops-code}
\end{figure}

\begin{figure}
\small
\begin{codebox}
\Procname{$\proc{Trap}(u; t_0, t_1; 
                       x_0, x_1, \id{dx}_0, \id{dx}_1; 
                       y_0, y_1, \id{dy}_0, \id{dy}_1)$}
\li $\Delta t \gets t_1 - t_0$
\li $\Delta x \gets \max\set{x_1-x_0, x_1+\id{dx}_1\Delta t - x_0+\id{dx}_0\Delta t}$
\li $\Delta y \gets \max\set{y_1-y_0, y_1+\id{dy}_1\Delta t - y_0+\id{dy}_0\Delta t}$
\li \If $\Delta x \geq 4\Delta t$ or $\Delta y \geq 4\Delta t$ 
         \Comment hyperspace cut \label{li:canCut}
\li      \Then \If $\Delta x \geq 4\Delta t$ \label{li:cutX}
\li       	        \Then Trisect the trapezoid with $x$-cuts
     		    \End
\li            \If $\Delta y \geq 4\Delta t$ 
\li                 \Then Trisect the trapezoid with $y$-cuts
               \End \label{li:cutY}
\li            Assign dependency levels to subtrapezoids
\li            Let $k$ be the maximum dependency level
\li  \For $i \gets 0$ \To $k$ \label{li:parallelSpawnBegin}
       \Comment for each dependency level $i$
\li 	\Do \Parfor all subtrapezoids 
\zi $\embox\embox$ $(t_0, t_1; x'_0, x'_1, \id{dx}'_0, \id{dx}'_1; y'_0, y'_1, \id{dy}'_0, \id{dy}'_1)$ 
\zi  $\embox\embox$ with dependency level $i$
\li    \Do    $\proc{Trap}(t_0, t_1; x'_0, x'_1, \id{dx}'_0, \id{dx}'_1; y'_0, y'_1, \id{dy}'_0, \id{dy}'_1)$ \label{li:parallelSpawnEnd}
    \End    \End 
%\li Return
\li \ElseIf $\Delta t > 1$ \Comment time cut \label{li:simTimeCutBegin}
\li \Then \Comment Recursively walk lower trapezoid and then the upper

\li  $\proc{Trap}(t_0, t_0 + \Delta t/2; 
                 x_0, x_1, \id{dx}_0, \id{dx}_1;
                 y_0, y_1, \id{dy}_0, \id{dy}_1)$
\li  $\proc{Trap}(t_0 + \Delta t/2, t_1;$
                 $x_0 + \id{dx}_0 \Delta t/2, x_1 + \id{dx}_1 \Delta t/2, \id{dx}_0, \id{dx}_1;$ 
\zi              $y_0 + \id{dy}_0 \Delta t/2, y_1 + \id{dy}_1 \Delta t/2, \id{dy}_0, \id{dy}_1)$ \label{li:simTimeCutEnd}
\li \Else \ \ \Comment base case \label{li:simBaseCaseBegin}
\li 	\For $t \gets t_0$ \To $t_1-1$ 
\li          \Do \For $x \gets x_0$ \To $x_1-1$
\li             \Do \For $y \gets y_0$ \To $y_1-1$
\li                 \Do $u((t+1)\bmod 2,x,y) \gets u(t\bmod 2,x,y) $
\zi  $\embox + \id{CX}\cdot ( u(t\bmod 2, (x-1)\bmod X, y) $
\zi  $\embox + u(t\bmod 2, (x+1)\bmod X, y) -2 u (t\bmod 2, x, y)) $
\zi  $\embox + \id{CY}\cdot ( u(t\bmod 2, x, (y-1)\bmod Y) $
\zi  $\embox + u(t\bmod 2, x, (y+1)\bmod Y) -2u(t\bmod 2, x, y) )$
	\End
	\End
	\End
\li \> $x_0 \pgets \id{dx}_0$
\li \> $x_1 \pgets \id{dx}_1$
\li \> $y_0 \pgets \id{dy}_0$
\li \> $y_1 \pgets \id{dy}_1$ \label{li:simBaseCaseEnd}
\End 
\end{codebox}

\caption{%
  The Pochoir cache-oblivious algorithm that implements a 2D stencil
  computation using a trapezoidal decomposition with hyperspace cuts.
  The parameter $u$ is an $X\times Y$ 2D array of grid points; $t_0$
  and $t_1$ are the beginning and ending time steps; $x_0$, $x_1$,
  $y_0$, and $y_1$ are the coordinates defining the base of the
  trapezoid; $dx_0$, $dx_1$, $dy_0$, and $dy_1$ are the slopes
  (actually inverse slopes) of the sides of the trapezoid.}
\label{fig:trap-code}
\end{figure}

\figref{trap-code} shows the pseudocode for the more efficient
algorithm for this stencil computation generated by the Pochoir
compiler.  We shall explain this algorithm in \secref{alg}.  It
achieves $\Theta(TXY/\cal B\sqrt{\cal M})$ cache misses, assuming that
$X\approx Y$ and $T=\Omega(X)$.  \proc{Trap} easily outperforms
\proc{Loops} on large data sets.  For example, we ran both algorithms
on a $5000 \times 5000$ space grid iterated for $5000$ time steps
using the Intel C++ version 12.0.0 compiler with Intel Cilk Plus
\cite{IntelCilkPlus10} on a 12-core Intel Core i7 (Nehalem) machine
with a private $32$-KB L1-data-cache, a private $256$-KB L2-cache, and
a shared $12$-MB L3-cache.  The code based on \proc{Loops} ran in
$248$ seconds, whereas the Pochoir-generated code based on \proc{Trap}
requires about $24$ seconds, producing more than a $10$ times
performance advantage.

\figref{benchmarks} shows Pochoir's performance on a wider range of
benchmarks, including
%
the heat equation (Heat) \cite{Epperson07} on a $2$D grid, a $2$D
torus, and a $4$D grid; Conway's game of Life (Life) \cite{Gardner70};
$3$D finite difference wave equation (Wave) \cite{Micikevicius09};
Lattice Boltzmann Method (LBM) \cite{MeiShYu00}; RNA secondary
structure prediction (RNA) \cite{ChowdhuryLeRa10,Akutsu00}; pairwise
sequence alignment (PSA) \cite{Gotoh82}; longest common subsequence
(LCS) \cite{CormenLeRi+09}; and American put stock option pricing
(APOP) \cite{John06}.
%
Pochoir achieves a substantial performance improvement over a
straightforward loop parallelization for typical stencil applications,
such as Heat and Life.  Even LBM, which is a complex stencil having
many states, achieves good speedup.  The benchmarks for which Pochoir
does not achieve as much speedup over the loop code are due to lack of
parallelism (too small spatial-time grid), containing
many branch conditionals in the innermost loop, or having a high ratio of
floating-point operations to memory accesses.  For example, RNA
suffers from both short of parallelism (the parallelism of RNA of grid 
size $300^2$ under Pochoir's trapezoidal algorithm is only a little above
$5$, which causes a heavy communication overhead associated with 
work-stealing scheme of Cilk when running on our 12 core Nehalem machine, 
and lots of branch conditionals in the innermost loop, while PSA operates 
over a diamond-shaped domain, and so the application employs incurs many
conditional branches in the kernel in order to distinguish interior
regions from the exterior.  These overheads can sometimes
significantly outweigh the benefits of incurring fewer cache misses
using a cache-efficient algorithm.

\newcommand{\chead}[1]{\multicolumn{1}{c}{\textit{#1}}}
\newcommand{\fhead}[1]{\multicolumn{2}{c|}{\textit{#1}}}

\begin{figure*}
\center
\small
\begin{tabular}{|llcr|rrr@{.}l|rr@{.}l|rr@{.}l|}
\hline
%\multicolumn{2}{|l}{\textit{Benchmark}}
\textit{Benchmark} & \textit{Dims}
& \textit{Grid} 
& \multicolumn{1}{c|}{\textit{Time}} 
% second group
& \multicolumn{4}{c|}{\textit{Pochoir}}
%& \fhead{Speedup}
% third group
& \multicolumn{3}{c|}{\textit{Serial loops}}
& \multicolumn{3}{c|}{\textit{$12$-core loops}}
 \\ 
%\multicolumn{2}{|r}{\textit{Dims}}
 &
 & \textit{size} & \multicolumn{1}{c|}{\textit{steps}}
% second group
& \textit{$1$ core} 
& \textit{$12$ cores}
& \fhead{speedup}
% third group
&\textit{time} & \fhead{ratio} & \textit{time} & \fhead{ratio} \\
%& & \fhead{} & & \fhead{}
%\\
%& & &
% second group
%& \chead{time} & \chead{time} & \fhead{speedup} 
% Third group
%& \textit{time} & \fhead{speedup} & \textit{time} & \fhead{speedup} \\
\hline\hline
Heat    & 2  & $16,000^2$        &     500 &   277s &  24s & 11&5  &   612s &  25&5 &   149s &  6&2  \\
Heat    & 2p & $16,000^2$        &     500 &   281s &  24s & 11&7  & 1,647s & 256&  &   248s & 10&3  \\
Heat    & 4  & $150^4$           &     100 &   154s &  54s &  2&9  &   433s &   8&0 &   104s &  1&9  \\
% Life  & 2  & $16,000^2$        &     500 &   931s &  77s & 12&09 &        &    &  &   410s &  5&32 \\
Life    & 2p & $16,000^2$        &     500 &   345s &  28s & 12&3  & 2,419s &  86&  &   332s & 11&8  \\
Wave    & 3  & $1,000^3$         &     500 & 3,082s & 447s &  6&89 & 3,170s &   7&1 & 1,071s &  2&39 \\
LBM     & 3  & $100^2\times 130$ &   3,000 &   345s &  68s &  5&1  &        &    &  &   220s &  3&2  \\
RNA     & 2  & $300^2$           &     900 &    90s &  20s &  4&5  &   121s &   6&1 &    26s &  1&3  \\
PSA     & 1  & $100,000$         & 200,000 &   105s &  18s &  5&8  &   432s &  24&  &    77s &  4&27  \\
LCS     & 1  & $100,000$         & 200,000 &    57s &   9s &  6&3  &   105s &  11&67  &    27s &  3&  \\
APOP    & 1  & $2,000,000$       &  10,000 &    43s &   4s & 11&   &   515s & 136&  &    48s & 13&   \\
%Game of Life on a Klein bottle: $16000^2$ spatial grid, 500 time steps                  & 965 & 80 & 12.06 & 350 & 4.37 \\
%Heat Diffusion on a Klein bottle: $16000^2$ spatial grid, 1000 time steps               & 603 & 52 & 11.59 & 432 & 8.3 \\
\hline
\end{tabular}
\caption{Pochoir performance on an Intel Core i7 (Nehalem) machine.
  The stencils are nonperiodic unless the \textit{Dims} column
  contains a~``p.''  The header \textit{Serial loops} means a serial
  \code{for} loop implementation running on one core, whereas
  \textit{$12$-core loops} means a parallel \code{cilk_for} loop
  implementation running on $12$ cores.  The header \textit{ratio}
  indicates how much slower the looping implementation is than the
  $12$-core Pochoir implementation.  For nonperiodic stencils, the
  looping implementations employ ghost cells \cite{Datta09} to avoid
  boundary processing.}
\label{fig:benchmarks}
\end{figure*}

Another alternative to the nested-loop implementation is exemplified
by the Berkeley autotuner \cite{Datta09,KamilShDa06,WilliamsCaOl08}.
K.~Datta and S.~Williams graciously gave us their code for computing a
7-point stencil and a 27-point stencil on a $258^3$ grid with ghost cells
using their system.  Unfortunately, since we were unable to reproduce the 
reported results from \cite{Datta09} --- presumably because there were 
too many differences in hardware, compilers, and operating system --- 
we are unable to offer a direct side-by-side comparison. Instead, we present
in \figref{berkeley} a comparison of our results to their reported
results.

We tried to make the operating conditions of the Pochoir tests as
similar as possible to the Berkeley environment reported
in~\cite{Datta09}.  We compared Pochoir running 8 worker threads on a
12-core system to the reported numbers for the Berkeley autotuner
running 8 threads on 8 cores.  The comparison may also result in a
disadvantage to Pochoir, because it had to cope with load imbalances
due to thread scheduling.  Likewise, the Berkeley figures may exhibit
a disadvantage compared with Pochoir.  Their reported numbers involve
only a single time step, however, whereas the Pochoir code runs for
$200$ time steps.  (It does not make sense to run Pochoir for only $1$
time step, since its efficiency is in large measure due to the
temporal locality of cache use.)  Notwithstanding these issues, as can
be seen from the figure, Pochoir's performance is generally comparable
to that of the Berkeley autotuner on these two benchmarks.

The Pochoir-generated \proc{Trap} code is a cache-oblivious
\cite{FrigoLePr99,Prokop99} divide-and-conquer algorithm based on the
notion of \defn{trapezoidal decompositions} introduced by Frigo and
Strumpen~\cite{FrigoSt05, FrigoSt09}.  We improve on their code by
using \defn{hyperspace} cuts, which produce an asymptotic improvement
in parallelism while attaining essentially the same cache efficiency.
As can be seen from \figref{trap-code}, however, this
divide-and-conquer parallel code is far more complex than
\proc{Loops}, involving recursion over irregular geometric regions.
Moreover, \proc{Trap} presents many opportunities for optimization,
including coarsening the base case of the recursion and handling
boundary conditions.  We contend that one cannot expect average
application programmers to be able to write such complex
high-performing code for each stencil computation they wish to
perform.

The Pochoir stencil compiler allows programmers to write simple
functional specification for arbitrary $d$-dimensional stencils, and
then it automatically produces a highly optimized, cache-efficient,
parallel implementation.  The Pochoir language can be viewed as a
domain-specific language \cite{Hudak96, MernikHeSl05,
  vanDeursenKlVi00} embedded in the base language C++ with the Cilk
multithreading extensions~\cite{IntelCilkPlus10}.

\begin{figure*}[t]
\centering
\begin{tabular}{c@{\hspace*{1cm}}c}
\includegraphics[clip,scale=0.5]{figures/Phase1.eps}
&
\includegraphics[clip,scale=0.5]{figures/Phase2.eps}\\
\textbf{(a)} & \textbf{(b)}
\end{tabular}
\caption{ Pochoir's two-phase compilation strategy.  \textbf{(a)}
  During Phase 1 the programmer uses the normal Intel C++ compiler to
  compile his or her code with the Pochoir template library.  Phase 1
  verifies that the programmer's stencil specification is Pochoir
  compliant.  \textbf{(b)} During Phase 2 the programmer uses the
  Pochoir compiler, which acts as a preprocessor to the Intel C++
  compiler, to generate optimized multithreaded Cilk code.}

\label{fig:phases}
\end{figure*}

\begin{figure}
\center
\small
\begin{tabular}{|c|c|c|}
\hline
                 & \textit{Berkeley}  & \textit{Pochoir}    \\ \hline
CPU              & Xeon X5550& Xeon X5650 \\
Clock            & $2.66$GHz & $2.66$ GHz \\
cores/socket     & 4         & 6          \\ 
Total \# cores   & 8         & 12         \\
Hyperthreading   & Enabled   & Disabled   \\
L1 data cache/core& $32$KB   &  $32$KB    \\
L2 cache/core    & $256$KB   & $256$KB    \\
L3 cache/socket  & $8$MB     & $12$ MB    \\
Peak computation & 85 GFLOPS & 120 GFLOPS \\ \hline
Compiler         & icc 10.0.0& icc 12.0.0 \\
Linux kernel     &           & 2.6.32     \\ 
Threading model  & Pthreads  & Cilk Plus  \\ 
Timing method    & Median time    & Elapsed time    \\ 
                 & of all threads &  \\ \hline
3D 7-point & 2.0 GStencil/s & 2.49 GStencil/s \\
8 cores    & 15.8 GFLOPS     & 19.92 GFLOPS \\ \hline
3D 27-point& 0.95 GStencil/s & 0.88 GStencil/s \\
8 cores    & 28.5 GFLOPS     & 26.4 GFLOPS \\ \hline
%3D 7-point &                & 2.24 GStencil/s \\
%12 cores   &                & 17.9 GFLOPS \\ \hline
%3D 27-point&                 & 1.25 GStencil/s \\
% 12 cores  &                 & 37.5 GFLOPS \\ \hline
\end{tabular}
\caption{A comparison of Pochoir to the reported results
  from~\cite{Datta09}.  The 7-point stencil requires 8 FLOP's per
  point, whereas the 27-point stencil requires 30 FLOP's per point.}
\label{fig:berkeley}
\end{figure}

The Pochoir system operates in two phases, as shown in
\figref{phases}, only the second of which involves the Pochoir
compiler itself.  For the first phase, the programmer compiles the
source program with the ordinary Intel C++ compiler using the Pochoir
template library, which implements Pochoir's linguistic constructs
using unoptimized but functionally correct algorithms.  This phase
ensures that the source program is \defn{Pochoir-compliant}.  For the
second phase, the programmer runs the source through the Pochoir
compiler, which acts as a preprocessor to the Intel C++ compiler,
performing a source-to-source translation into a postsource C++
program that employs the Cilk extensions.  The postsource is then
compiled with the Intel compiler to produce the optimized binary
executable.  The Pochoir compiler makes the following promise:
\begin{quote}
  \textbf{The Pochoir Guarantee:} If the stencil program compiles and
  runs with the Pochoir template library during Phase 1, no errors
  will occur during Phase 2 when it is compiled with the Pochoir
  compiler or during the subsequent running of the optimized binary.
\end{quote}

Pochoir's novel two-phase compilation strategy allowed us to build
significant domain-specific optimizations into the Pochoir compiler
without taking on the massive job of parsing and type-checking the
full C++ language.  Knowing that the source program compiles
error-free with the Pochoir template library during Phase 1 allows the
Pochoir compiler in Phase 2 to treat portions of the source as
uninterpreted text, confident that the Intel compiler will compile it
correctly in the optimized postsource.  Moreover, the Pochoir template
library allows the programmer to debug his or her code using a
comfortable native C++ tool chain without the complications of the
Pochoir compiler.

\begin{figure}[t]
\begin{center-code}
\lstset{language=Pochoir_bf}
\begin{pochoir-listing}
#define mod(r,m) ((r)%(m) + ((r)<0)? (m):0)[@\\@]
Pochoir_Boundary_2D(heat_bv, a, t, x, y) [@\label{li:heat:Boundary:begin}@]
  return a.get(t,mod(x,a.size(1)),mod(y,a.size(0)));[@\label{li:heat:returnValue}@]
Pochoir_Boundary_End [@\label{li:heat:Boundary:end}@] [@\\@]
int main(void) { [@\\@]
  Pochoir_Shape_2D 2D_five_pt[] = {{1,0,0}, {0,1,0}, {0,-1,0}, {0,-1,-1}, {0,0,-1}, {0,0,1}}; [@\label{li:heat:Shape:decl}@] 
  Pochoir_2D heat(2D_five_pt); [@\label{li:heat:Pochoir:decl}@] [@\\@]
  Pochoir_Array_2D(double) u(X, Y); [@\label{li:heat:Array:decl}@]
  u.Register_Boundary(heat_bv); [@\label{li:Array:regBdry}@] 
  heat.Register_Array(u); [@\label{li:heat:regArray}@] [@\\@]
  Pochoir_Kernel_2D(heat_fn, t, x, y) [@\label{li:heat:Kernel:begin}@]
    u(t+1, x, y) = CX * (u(t, x+1, y) - 2 * u(t, x, y) + u(t, x-1, y)) + CY * (u(t, x, y+1) - 2 * u(t, x, y) + u(t, x, y-1)) + u(t, x, y);
  Pochoir_Kernel_End [@\label{li:heat:Kernel:end}@] [@\\@]
  for (int x = 0; x < X; ++x) [@\label{li:heat:init:begin}@]
    for (int y = 0; y < Y; ++y)    
      u(0, x, y) = rand();  [@\label{li:heat:init:end}@]  [@\\@]
  heat.Run(T, heat_fn); [@\label{li:heat:run}@] [@\\@]
  for (int x = 0; x < X; ++x) [@\label{li:heat:print:begin}@]
    for (int y = 0; y < Y; ++y)    
      cout << u(T, x, y);  [@\label{li:heat:print:end}@]  [@\\@]

  return 0;
}
\end{pochoir-listing}
\end{center-code}  
\caption{The Pochoir stencil source code for a periodic 2D heat
  equation.  Pochoir keywords are boldfaced.}
\label{fig:2DHeat}
\end{figure}

\figref{2DHeat} shows the Pochoir source code for the periodic 2D heat
equation.  We leave the specification of the Pochoir language to
\secref{spec}, but outline the salient features of the language using
this code as an example.

\Liref{heat:Shape:decl} declares the \defn{Pochoir shape} of the
stencil, and \liref{heat:Pochoir:decl} creates the 2-dimensional
\defn{Pochoir object} \code{heat} having that shape.  The Pochoir
object will contain all the state necessary to perform the
computation.  Each triple in the array \code{2D_five_pt} corresponds
to the relative offsets from the space-time grid point $(t, x, y)$
that will be accessed by the stencil kernel (declared in
\lirefs{heat:Kernel:begin}{heat:Kernel:end}).  The compiler cannot
infer the stencil shape from the kernel, because the kernel can be
arbitrary code, and accesses to the grid points can be hidden in
subroutines.  The Pochoir template library complains during Phase~1,
however, if an access to a grid point during the kernel computation
falls outside the region specified by the shape declaration.

\Liref{heat:Array:decl} declares \code{u} as an
\code{X}$\times$\code{Y} \defn{Pochoir array} of double-precision
floating-point numbers representing the spatial grid.
\Lirefs{heat:Boundary:begin}{heat:Boundary:end} define a
\defn{boundary function} that will be called when the kernel procedure
accesses grid points outside the computing domain, that is, if it
tries to access \code{u(t, x, y)} with \code{x} $<0$, \code{x} $\geq$
\code{X}, \code{y} $<0$, or \code{y} $\geq$ \code{Y}.  The boundary
function for this periodic stencil performs calculations modulo the
dimensions of the spatial grid.  (\secref{spec} shows how nonperiodic
stencils can be specified, including how to specify Dirichlet and
Neumann boundary conditions~\cite{FeshbachMo81}.)
\Liref{Array:regBdry} associates the boundary function \code{heat_bv}
with the Pochoir array~\code{u}.  Each Pochoir array has exactly one
boundary function to supply a value when the computation accesses grid
points outside of the computing domain.  \Liref{heat:regArray}
registers the Pochoir array \code{u} with the \code{heat} Pochoir
object.  A Pochoir array can be registered with more than one Pochoir
object, and a Pochoir object can have multiple Pochoir arrays
registered.

\Lirefs{heat:Kernel:begin}{heat:Kernel:end} define a \defn{kernel
  function} \code{heat_fn}, which specifies how the stencil is
computed for every grid point.  This kernel can be an arbitrary piece
of code, but accesses to the registered Pochoir arrays must respect
the declared shape(s).

\Lirefs{heat:init:begin}{heat:init:end} initialize the Pochoir array
\code{u} with values for time step~$0$.  If a stencil depends on more
than one prior step as indicated by the Pochoir shape, multiple time
steps may need to be initialized.  \Liref{heat:run} executes the
stencil object \code{heat} for $T$ time steps using kernel function
\code{heat_fn}.  \Lirefs{heat:print:begin}{heat:print:end} prints the
result of the computation by reading the elements \code{u(T, x, y)} of
the Pochoir array.  In fact, Pochoir overloads the ``\code{<<}''
operator so that the Pochoir array can be pretty-printed by simply
writing ``\code{cout << u;}''.

The remainder of this paper is organized as follows.  \secref{spec}
provides a full specification of the Pochoir embedded language.
\secref{alg} describes the cache-efficient parallel algorithm used by
the compiled code and analyzes its theoretical performance.
\secref{opt} describes how the Pochoir system works.  \secref{rel}
describes related work, and \secref{concl} concludes with a brief
discussion of open issues.


% LocalWords:  Pochoir multicore spacetime parallelizing multithreaded Frigo
% LocalWords:  discretizing pseudocode parallelized Strumpen multithreading
% LocalWords:  Cilk Pochoir's preprocessor postsource nonperiodic Nehalem Datta
% LocalWords:  Neumann Subsequence subtrapezoids parallelization Hyperthreading
% LocalWords:  FLOP's autotuner subsequence

% -*- Mode: LaTeX -*-
\secput{intro}{Introduction}

Pochoir (pronounced ``PO-shwar'') is a compiler and run-time system
for implementing stencil computations on multicore processors.  A
\defn{stencil} defines the value of a grid point in a $d$-dimensional
spatial grid at time $t$ as a function of neighboring grid points at
recent times before~$t$.  A \defn{stencil computation}
\cite{FrigoSt05, FrigoSt09, DattaMuVo08, KamilShDa06, KamilShHu05, Nitsure06,
KrishnamoorthyBaBo07, DursunNoWa09, PengSeNo09, DursunNoPe09, BleckRoDi92,
NakanoKaVa92, TafloveHa00, WilliamsCaOl08 }
computes the stencil for each grid point over many time
steps.

Stencil computations are conceptually simple to implement using nested
loops, but looping implementations suffer from poor cache performance.
Cache-oblivious \cite{FrigoLePr99,Prokop99} divide-and-conquer stencil
codes \cite{FrigoSt05, FrigoSt09} are much more efficient, but they
are difficult to write, and when parallelism is factored into the mix,
most application programmers do not have the programming skills or
patience to produce efficient multithreaded codes.

As an example, consider how the 2D
\defn{heat equation} \cite{Epperson07}
\begin{equation}
  \frac{\partial u_t(x,y)}{\partial t} 
    = \alpha \paren{\frac{\partial^2 u_t(x,y)}{ \partial x^2} 
      + \frac{\partial^2 u_t(x,y)}{ \partial y^2}}
      \label{eq:heat2d}
\end{equation}
on an $X\times Y$ grid, where $u_t(x,y)$ is the heat at a point
$(x,y)$ at time $t$ and $\alpha$ is the thermal diffusivity, might be
solved using a stencil computation.  By discretizing space and time,
this partial differential equation can be solved approximately by
using the following update equation:
\begin{eqnarray}
  u_{t+1}(x,y)  & = & u_t(x,y) \nonumber\\
  & & +  \frac{\alpha \Delta t}{\Delta x^2}
  \paren{ u_t(x-1,y) + u_t(x+1,y) - 2 u_t(x,y)}\nonumber \\
  & &  + \frac{\alpha \Delta t}{\Delta y^2} 
  \paren{u_t(x,y-1) + u_t(x,y+1) - 2u_t(x,y)} \ .
  \label{eq:heat2d-update}
\end{eqnarray}
  
One simple parallel program to implement the stencil of
\eqref{heat2d-update} is with a triply nested loop, as shown in
\figref{loops-code}.  The code is invoked as $\proc{Loops}(u; 0, T; 0,
X; 0, Y)$ to perform the stencil computation over $T$ time steps.
Although the loop indexing the time dimension is serial, the loops
indexing the spatial dimensions can be parallelized.  As a practical
matter, there is generally no need to store the entire space-time
grid, and so the code uses two copies of the space grid, swapping
their roles on alternate time steps.  This code assumes that the
boundary conditions are \defn{periodic}, meaning that the space grid
wraps around to form a torus, and hence the index calculations for $x$
and $y$ are performed modulo $X$ and $Y$, respectively.

This loop nest is simple and fairly easy to understand, but its
performance may suffer from poor cache locality.  Let the total number
of grid points in the space-time grid be $N=TXY$, let $\cal M$ be the
number of grid points that fit in cache, and let $\cal B$ be the
number of grid points that fit on a cache line.  If the space grid
does not fit in cache, then this simple computation incurs
$\Theta(N/\cal B)$ cache misses in the ideal-cache
model~\cite{FrigoLePr99}.

\begin{figure}
\small
\begin{codebox}
\Procname{$\proc{Loops}(u; t_0, t_1; x_0, x_1; y_0, y_1)$}
\li       \For $t \gets t_0$ \To $t_1-1$ 
\li          \Do \Parfor $x \gets x_0$ \To $x_1-1$
\li             \Do \Parfor $y \gets y_0$ \To $y_0-1$
\li                 \Do $u((t+1)\bmod 2,x,y) \gets u(t\bmod 2,x,y) $
\zi  $\embox + \id{CX}\cdot ( u(t\bmod 2, (x-1)\bmod X, y) $
\zi  $\embox + u(t\bmod 2, (x+1)\bmod X, y) -2 u (t\bmod 2, x, y) ) $
\zi  $\embox + \id{CY}\cdot ( u(t\bmod 2, x, (y-1)\bmod Y) $
\zi  $\embox + u(t\bmod 2, x, (y+1)\bmod Y) -2u(t\bmod 2, x, y) )$
\End\End\End
\end{codebox}

\caption{A parallel looping implementation of a stencil computation
  for the 2D heat equation with periodic boundary conditions.  The
  array $u$ keeps two copies of an $X\times Y$ array of grid points,
  one for time $t$ and one for time $t+1$.  The parameters $t_0$ and
  $t_1$ are the beginning and ending time steps, and $x_0$, $x_1$,
  $y_0$, and $y_1$ are the coordinates defining the region of the
  array $u$ on which to perform the stencil computation.  The call
  $\proc{Loops}(u; 0, T; 0, X; 0, Y)$ performs the stencil computation
  over the whole 2D array for $T$ time steps.}
\label{fig:loops-code}
\end{figure}

\begin{figure}
\small
\begin{codebox}
\Procname{$\proc{Trap}(u; t_0, t_1; 
                       x_0, x_1, \id{dx}_0, \id{dx}_1; 
                       y_0, y_1, \id{dy}_0, \id{dy}_1)$}
\li $\Delta t \gets t_1 - t_0$
\li \If $x_1 - x_0 \geq 4\Delta t$ or $y_1 - y_0 \geq 4\Delta t$ 
         \Comment hyperspace cut \label{li:canCut}
\li      \Then \If $x_1 - x_0 \geq 4\Delta t$ \label{li:cutX}
\li       	        \Then Cut the trapezoid normal to the $x$-dimension
     		    \End
\li            \If $y_1 - y_0 \geq 4\Delta t$ 
\li                 \Then Cut the trapezoid normal to the $y$-dimension
               \End \label{li:cutY}
\li            Assign dependency levels to subtrapezoids
\li            Let $k$ be the maximum dependency level
\li  \For $i \gets 0$ \To $k$ \label{li:parallelSpawnBegin}
       \Comment for each dependency level $i$
\li 	\Do \Parfor all subtrapezoids 
\zi $\embox\embox$ $(t_0, t_1; x'_0, x'_1, \id{dx}'_0, \id{dx}'_1; y'_0, y'_1, \id{dy}'_0, \id{dy}'_1)$ 
\zi  $\embox\embox$ with dependency level $i$
\li    \Do    $\proc{Trap}(t_0, t_1; x'_0, x'_1, \id{dx}'_0, \id{dx}'_1; y'_0, y'_1, \id{dy}'_0, \id{dy}'_1)$ \label{li:parallelSpawnEnd}
    \End    \End 
%\li Return
\li \ElseIf $\Delta t > 1$ \Comment time cut \label{li:simTimeCutBegin}
\li \Then \Comment Recursively walk lower trapezoid and then the upper

\li  $\proc{Trap}(t_0, t_0 + \Delta t/2; 
                 x_0, x_1, \id{dx}_0, \id{dx}_1;
                 y_0, y_1, \id{dy}_0, \id{dy}_1)$
\li  $\proc{Trap}(t_0 + \Delta t/2, t_1;$
                 $x_0 + \id{dx}_0 \Delta t/2, x_1 + \id{dx}_1 \Delta t/2, \id{dx}_0, \id{dx}_1;$ 
\zi              $y_0 + \id{dy}_0 \Delta t/2, y_1 + \id{dy}_1 \Delta t/2, \id{dy}_0, \id{dy}_1)$ \label{li:simTimeCutEnd}
\li \Else \ \ \Comment base case \label{li:simBaseCaseBegin}
\li 	\For $t \gets t_0$ \To $t_1-1$ 
\li          \Do \For $x \gets x_0$ \To $x_1-1$
\li             \Do \For $y \gets y_0$ \To $y_1-1$
\li                 \Do $u((t+1)\bmod 2,x,y) \gets u(t\bmod 2,x,y) $
\zi  $\embox + \id{CX}\cdot ( u(t\bmod 2, (x-1)\bmod X, y) $
\zi  $\embox + u(t\bmod 2, (x+1)\bmod X, y) -2 u (t\bmod 2, x, y)) $
\zi  $\embox + \id{CY}\cdot ( u(t\bmod 2, x, (y-1)\bmod Y) $
\zi  $\embox + u(t\bmod 2, x, (y+1)\bmod Y) -2u(t\bmod 2, x, y) )$
	\End
	\End
	\End
\li \> $x_0 \pgets \id{dx}_0$
\li \> $x_1 \pgets \id{dx}_1$
\li \> $y_0 \pgets \id{dy}_0$
\li \> $y_1 \pgets \id{dy}_1$ \label{li:simBaseCaseEnd}
\End 
\end{codebox}

\caption{%
  The Pochoir cache-oblivious algorithm that implements a 2D stencil
  computation using a trapezoidal decomposition with hyperspace cuts.
  The parameter $u$ is an $X\times Y$ 2D array of grid points; $t_0$
  and $t_1$ are the beginning and ending time steps; $x_0$, $x_1$,
  $y_0$, and $y_1$ are the coordinates defining the base of the
  trapezoid; $dx_0$, $dx_1$, $dy_0$, and $dy_1$ are the slopes
  (actually inverse slopes) of the sides of the trapezoid.}
\label{fig:trap-code}
\end{figure}

\figref{trap-code} shows the pseudocode for the more efficient
algorithm for this stencil computation that the Pochoir compiler
generates and which achieves $\Theta(N/\cal B\sqrt{\cal M})$ cache
misses.  We shall explain this algorithm in \secref{alg}.  \proc{Trap}
easily outperforms \proc{Loops} on large data sets.  For example, we
ran both algorithms on a $5000 \times 5000$ space grid iterated for
$5000$ time steps using the Intel C++ version 12.0.0 compiler with
Intel Cilk Plus \cite{IntelCilkPlus10} on a 12-core Intel Core i7
(Nehalem) machine with a private $32$-KB L1-data-cache, a private
$256$-KB L2-cache, and a shared $12$-MB L3-cache.  The code based on
\proc{Loops} ran in $248$ seconds, whereas the Pochoir-generated code
based on \proc{Trap} requires about $24$ seconds, producing more than
a $10$ times performance advantage.

\figref{benchmarks} shows Pochoir's performance on a wider range of
benchmarks, including
 $2$D heat equation (both with periodic and aperiodic boundary conditions) \cite{Epperson07},
 $4$D heat equation \cite{Epperson07},
 Conway's game of Life \cite{Gardner70},
 $3$D finite difference wave equation \cite{Micikevicius09}, 
 Lattice Boltzmann Method (LBM) \cite{MeiShYu00},
 RNA secondary structure prediction \cite{ChowdhuryLeRa10,Akutsu00},
 pairwise sequence alignment (PSA) \cite{Gotoh82},
 longest common subsequence (LCS) \cite{CormenLeRi+09}, and
 American put stock option pricing \cite{John06}.
Pochoir achieves a substantial performance improvement over a
straightforward loop parallelization for typical stencil applications,
such heat, and Life.  Even the Lattice Boltzmann Method, which is a
complex stencil having many states, achieves good speedup.  The
benchmarks for which Pochoir does not achieve as much speedup over the
loop code either contain many branch conditionals in the innermost
loop or have a high ratio of floating-point operations to memory
accesses.  For example, RNA suffers from both disadvantages while PSA
operates over a diamond-shaped domain, and so the application employs
incurs many conditional branches in the kernel in order to distinguish
interior regions from the exterior.  These two overheads can sometimes
significantly outweigh the benefits of incurring fewer cache misses
using a cache-efficient algorithm.

\begin{figure*}
\center
\small
\begin{tabular}{|lcccc|ccc|cc|}
\hline
\textit{Benchmark} 
& \makebox[0.1in]{\textit{Dims}} % make this smaller to get things to fit
& \textit{Grid} 
&  \textit{Time} & \textit{Periodic} &\textit{Pochoir}  
& \textit{Pochoir}    & \textit{Speedup} 
& \textit{Loops}      & \textit{Loops/Pochoir}
 \\ 
& & \textit{Size} & \textit{Steps} & & \textit{time} 
& \textit{time} & 
& \textit{time} & \textit{time}    
\\
& & & & & \textit{$1$ core} 
& \textit{$12$ cores} & 
& \textit{$12$ cores} & \textit{$12$ cores}    
\\
\hline\hline
Heat    & 2 & $16000^2$ & 500  & No & 277 & 24 & 11.54 & 149 & 6.20 \\
Heat    & 2 & $16000^2$ & 500  & Yes & 281 & 24 & 11.70 & 248 & 10.33 \\
%Life   & 2 & $16000^2$ & Yes & 500 & 931 & 77 & 12.09 & 410 & 5.32 \\
Life    & 2 & $16000^2$ & 500 & Yes & 345 & 28 & 12.32 & 332 & 11.85 \\
Wave    & 3 & $1000^3$ & 500 & No & 3082 & 447 & 6.89 & 1071 &  2.39 \\
LBM     & 3 & $100^2\times 130$ & 3000 & No  & 345 & 68 & 5.07 & 220 & 3.24 \\
RNA & 2 & $300^2$ & 900 & No & 90 & 20 & 4.5 & 26 & 1.29 \\
PSA     & 1 & $100000$ & 200000 & No & 150 & 18 & 8.33 & 53 & 2.93 \\
LCS     & 1 & $100000$ & 200000 & No & 68 & 9 & 7.55 & 25 & 2.60 \\
Heat    & 4 & $150^4$ & 100 & No & 154 & 54 & 2.85 & 104 & 1.92 \\
Options & 1 & $2000000$ & 10000 & No & 333 & 28 & 11.89 & 54 & 1.92 \\
%Game of Life on a Klein bottle: $16000^2$ spatial grid, 500 time steps                  & 965 & 80 & 12.06 & 350 & 4.37 \\
%Heat Diffusion on a Klein bottle: $16000^2$ spatial grid, 1000 time steps               & 603 & 52 & 11.59 & 432 & 8.3 \\
\hline
\end{tabular}
\caption{Pochoir performance on an Intel Core i7 (Nehalem) machine.
  All times are in seconds. \id{Loops} means a parallel \code{for}
  loop implementation.  For nonperiodic stencils, the \id{Loops}
  implementation employs ghost cells \cite{Datta09} to avoid boundary
  processing.}
\label{fig:benchmarks}
\end{figure*}

Another alternative to the nested-loop implementation is exemplified
by the Berkeley autotuner \cite{Datta09,KamilShDa06,WilliamsCaOl08}.
K.~Datta and S.~Williams graciously gave us their code for computing a
7-point stencil and a 27-point stencil on a $258^3$ grid using their
system.  Unfortunately, since we were unable to reproduce the reported
results from \cite{Datta09} --- presumably because there were too many
differences in hardware, compilers, and operating system --- we are
unable to offer a direct side-by-side comparison.  Instead, we present
in \figref{berkeley} a comparison of our results to their reported
results.

We tried to make the operating conditions of the Pochoir tests as
similar as possible to the Berkeley environment reported
in~\cite{Datta09}.  We compared Pochoir running 8 worker threads on a
12-core system to the reported numbers for the Berkeley autotuner
running 8 threads on 8 cores.  The comparison may also result in a
disadvantage to Pochoir, because it had to cope with load imbalances
due to thread scheduling.  Likewise, the Berkeley figures may exhibit
a disadvantage compared with Pochoir.  Their reported numbers involve
only a single time step, however, whereas the Pochoir code runs for
$200$ time steps.  (It does not make sense to run Pochoir for only $1$
time step, since its efficiency is in large measure due to the
temporal locality of cache use.)  Notwithstanding these issues, as can
be seen from the figure, Pochoir's performance is generally comparable
to that of the Berkeley autotuner on these two benchmarks.

The Pochoir-generated \proc{Trap} code is a cache-oblivious
\cite{FrigoLePr99,Prokop99} divide-and-conquer algorithm based on the
notion of \defn{trapezoidal decompositions} introduced by Frigo and
Strumpen~\cite{FrigoSt05, FrigoSt09}.  We improve on their code by
using \defn{hyperspace} cuts, which produce an asymptotic improvement
in parallelism while attaining essentially the same cache efficiency.
As can be seen from \figref{trap-code}, however, this
divide-and-conquer parallel code is far more complex than
\proc{Loops}, involving recursion over irregular geometric regions.
Moreover, \proc{Trap} presents many opportunities for optimization,
including coarsening the base case of the recursion and handling
boundary conditions.  We contend that one cannot expect average
application programmers to be able to write such complex
high-performing code for each stencil computation they wish to
perform.

The Pochoir stencil compiler allows programmers to write simple
functional specification for arbitrary $d$-dimensional stencils, and
then it automatically produces a highly optimized, cache-efficient,
parallel implementation.  The Pochoir language can be viewed as a
domain-specific language \cite{Hudak96, MernikHeSl05,
  vanDeursenKlVi00} embedded in the base language C++ with the Cilk
multithreading extensions~\cite{IntelCilkPlus10}.

\begin{figure*}[t]
\centering
\begin{tabular}{c@{\hspace*{1cm}}c}
\includegraphics[clip,scale=0.5]{figures/Phase1.eps}
&
\includegraphics[clip,scale=0.5]{figures/Phase2.eps}\\
\textbf{(a)} & \textbf{(b)}
\end{tabular}
\caption{ Pochoir's two-phase compilation strategy.  \textbf{(a)}
  During Phase 1 the programmer uses the normal Intel C++ compiler to
  compile his or her code with the Pochoir template library.  Phase 1
  verifies that the programmer's stencil specification is Pochoir
  compliant.  \textbf{(b)} During Phase 2 the programmer uses the
  Pochoir compiler, which acts as a preprocessor to the Intel C++
  compiler, to generate optimized multithreaded Cilk code.}

\label{fig:phases}
\end{figure*}

\begin{figure}
\center
\small
\begin{tabular}{|c|c|c|}
\hline
                 & \textit{Berkeley}  & \textit{Pochoir}    \\ \hline
CPU              & Xeon X5550& Xeon X5650 \\
Clock            & $2.66$GHz & $2.66$ GHz \\
cores/socket     & 4         & 6          \\ 
Total \# cores   & 8         & 12         \\
Hyperthreading   & Enabled   & Disabled   \\
L1 data cache/core& $32$KB   &  $32$KB    \\
L2 cache/core    & $256$KB   & $256$KB    \\
L3 cache/socket  & $8$MB     & $12$ MB    \\
Peak computation & 85 GFLOPS & 120 GFLOPS \\ \hline
compiler         & icc 10.0.0& icc 12.0.0 \\
Linux kernel     &           & 2.6.32     \\ 
threading model  & Pthreads  & Cilk Plus  \\ \hline
3D 7-point & 2.0 GStencil/s & 2.46 GStencil/s \\
8 cores    & 15.8 GFLOPS     & 19.68 GFLOPS \\ \hline
3D 27-point& 0.95 GStencil/s & 0.88 GStencil/s \\
8 cores    & 28.5 GFLOPS     & 26.4 GFLOPS \\ \hline
%3D 7-point &                & 2.24 GStencil/s \\
%12 cores   &                & 17.9 GFLOPS \\ \hline
%3D 27-point&                 & 1.25 GStencil/s \\
% 12 cores  &                 & 37.5 GFLOPS \\ \hline
\end{tabular}
\caption{A comparison of Pochoir to the reported results
  from~\cite{Datta09}.  The 7-point stencil requires 8 FLOP's per
  point, whereas the 27-point stencil requires 30 FLOP's per point.}
\label{fig:berkeley}
\end{figure}

The Pochoir system operates in two phases, as shown in
\figref{phases}, only the second of which involves the Pochoir
compiler itself.  For the first phase, the programmer compiles the
source program with the ordinary Intel C++ compiler using the Pochoir
template library, which implements Pochoir's linguistic constructs
using unoptimized but functionally correct algorithms.  This phase
ensures that the source program is \defn{Pochoir-compliant}.  For the
second phase, the programmer runs the source through the Pochoir
compiler, which acts as a preprocessor to the Intel C++ compiler,
performing a source-to-source translation into a postsource C++
program that employs the Cilk extensions.  The postsource is then
compiled with the Intel compiler to produce the optimized binary
executable.  The Pochoir compiler makes the following promise:
\begin{quote}
  \textbf{The Pochoir Guarantee:} If the stencil program compiles and
  runs with the Pochoir template library during Phase 1, no errors
  will occur during Phase 2 when it is compiled with the Pochoir
  compiler or during the subsequent running of the optimized binary.
\end{quote}

Pochoir's novel two-phase compilation strategy allowed us to build
significant domain-specific optimizations into the Pochoir compiler
without taking on the massive job of parsing and type-checking the
full C++ language.  Knowing that the source program compiles
error-free with the Pochoir template library during Phase 1 allows the
Pochoir compiler in Phase 2 to treat portions of the source as
uninterpreted text, confident that the Intel compiler will compile it
correctly in the optimized postsource.  Moreover, the Pochoir template
library allows the programmer to debug his or her code using a
comfortable native C++ tool chain without the complications of the
Pochoir compiler.

\begin{figure}[t]
\begin{center-code}
\lstset{language=Pochoir_bf}
\begin{pochoir-listing}
Pochoir_2D heat; [@\label{li:heat:Pochoir:decl}@] [@\\@]
Pochoir_Shape_2D heat_shape[] = { {1,0,0}, {0,1,0}, {0,-1,0}, {0,-1,-1}, {0,0,-1}, {0,0,1} }; [@\label{li:heat:Shape:decl}@] 
heat.Register_Shape(heat_shape); [@\label{li:heat:regShape}@] [@\\@]
Pochoir_Array_2D(double) u(X, Y); [@\label{li:heat:Array:decl}@] 
Pochoir_Boundary_2D(heat_bv, arr, t, x, y) [@\label{li:heat:Boundary:begin}@]
    return arr.get(t, x%arr.size(1), y%arr.size(0));[@\label{li:heat:returnValue}@]
Pochoir_Boundary_End [@\label{li:heat:Boundary:end}@]
heat.Register_Array(u, heat_bv); [@\label{li:heat:regArray}@] [@\\@]
Pochoir_Kernel_2D(heat_fn, t, x, y) [@\label{li:heat:Kernel:begin}@]
    u(t+1, x, y) = CX * (u(t, x+1, y) - 2.0 * u(t, x, y) + u(t, x-1, y)) + CY * (u(t, x, y+1) - 2.0 * u(t, x, y) + u(t, x, y-1)) + u(t, x, y);
Pochoir_Kernel_End [@\label{li:heat:Kernel:end}@] [@\\@]
for (int x = 0; x < X; ++x) [@\label{li:heat:init:begin}@]
  for (int y = 0; y < Y; ++y)    
     u(0, x, y) = rand();  [@\label{li:heat:init:end}@]  [@\\@]
heat.Run(T, heat_fn); [@\label{li:heat:run}@]
\end{pochoir-listing}
\end{center-code}  
\caption{The Pochoir stencil source code for a periodic 2D heat
  equation.  Pochoir keywords are boldfaced.}
\label{fig:2DHeat}
\end{figure}

\figref{2DHeat} shows the Pochoir source code for the periodic 2D heat
equation.  We leave the specification of the Pochoir language to
\secref{spec}, but outline the salient features of the language using
this code as an example.

\Liref{heat:Pochoir:decl} declares a \defn{Pochoir object} named
\code{heat} having 2 dimensions.  This object will contain all the
state necessary to perform the computation.

\Liref{heat:Shape:decl} declares the \defn{Pochoir shape} of the
stencil, and \liref{heat:regShape} registers it with \code{heat}.
Each triple in the array \code{heat_shape} corresponds to the relative
offsets from the space-time grid point $(t, x, y)$ that will be
accessed by the stencil kernel (declared in
\lirefs{heat:Kernel:begin}{heat:Kernel:end}).  The compiler cannot
infer the stencil shape from the kernel, because the kernel can be
arbitrary code, and accesses to the grid points can be hidden in
subroutines.  The Pochoir template library will complain during
Phase~1, however, if an access to a grid point during the kernel
computation falls outside the region specified by the shape
declaration.

\Liref{heat:Array:decl} declares \code{u} as an
\code{X}$\times$\code{Y} \defn{Pochoir array} of double-precision
floating-point numbers representing the spatial grid.
\Lirefs{heat:Boundary:begin}{heat:Boundary:end} define a
\defn{boundary function} that will be called when the kernel procedure
accesses grid points outside the computing domain, that is, if it
tries to access \code{u(t, x, y)} with \code{x} $<0$, \code{x} $\geq$
\code{X}, \code{y} $<0$, or \code{y} $\geq$ \code{Y}.  The boundary
function for this periodic stencil performs calculations modulo the
dimensions of the spatial grid.  (\secref{spec} shows how nonperiodic
stencils can be specified, including how to specify Dirichlet and
Neumann boundary conditions~\cite{FeshbachMo81}.)
\Liref{heat:regArray} registers the Pochoir array \code{u} and its
boundary function \code{heat_bf} with the \code{heat} Pochoir object.
A Pochoir array can be registered with more than one Pochoir object,
and a Pochoir object can have more than one Pochoir array registered.

\Lirefs{heat:Kernel:begin}{heat:Kernel:end} define a \defn{kernel
  function} \code{heat_fn}, which specifies how the stencil is
computed for every grid point.  This kernel can be an arbitrary piece
of code, but accesses to the registered Pochoir arrays must respect
the declared shape(s).

\Lirefs{heat:init:begin}{heat:init:end} initialize the Pochoir array
\code{u} with values for time step~$0$.  If a stencil depends on more
than one prior step as indicated by the Pochoir shape, multiple time
steps may need to be initialized.  \Liref{heat:run} executes the
stencil object \code{heat} for $T$ time steps using kernel function
\code{heat_fn}.  The user can then obtain the final result by reading
the elements \code{u(T, x, y)} of the Pochoir array.

The remainder of this paper is organized as follows.  \secref{spec}
provides a full specification of the Pochoir embedded language.
\secref{alg} describes the cache-efficient parallel algorithm used by
the compiled code and analyzes its theoretical performance.
\secref{opt} describes how the Pochoir system works.  \secref{rel}
describes related work, and \secref{concl} concludes with a brief
discussion of open issues.


% LocalWords:  Pochoir multicore spacetime parallelizing multithreaded Frigo
% LocalWords:  discretizing pseudocode parallelized Strumpen multithreading
% LocalWords:  Cilk Pochoir's preprocessor postsource nonperiodic Nehalem Datta
% LocalWords:  Neumann Subsequence subtrapezoids parallelization Hyperthreading
% LocalWords:  FLOP's autotuner
